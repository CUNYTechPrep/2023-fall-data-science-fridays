{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283c90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c7befd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14)\n",
      "[[1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
      " [0 0 1 0 0 0 0 0 1 0 1 0 0 1]\n",
      " [0 0 2 1 1 1 1 0 0 0 1 0 1 1]\n",
      " [0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 2 0 0 0 1 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X = [\"Jim and Pam traveled by the bus\", \"The bus was late.\", \"The bus was full. Traveling by bus is expensive.\", 'bus bus bus', 'the bus bus is awesome']\n",
    "\n",
    "#using the count vectorizer\n",
    "count = CountVectorizer()\n",
    "word_count=count.fit_transform(X)\n",
    "print(word_count.shape)\n",
    "print(word_count.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b40bf6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>awesome</th>\n",
       "      <th>bus</th>\n",
       "      <th>by</th>\n",
       "      <th>expensive</th>\n",
       "      <th>full</th>\n",
       "      <th>is</th>\n",
       "      <th>jim</th>\n",
       "      <th>late</th>\n",
       "      <th>pam</th>\n",
       "      <th>the</th>\n",
       "      <th>traveled</th>\n",
       "      <th>traveling</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  awesome  bus  by  expensive  full  is  jim  late  pam  the  traveled  \\\n",
       "0    1        0    1   1          0     0   0    1     0    1    1         1   \n",
       "1    0        0    1   0          0     0   0    0     1    0    1         0   \n",
       "2    0        0    2   1          1     1   1    0     0    0    1         0   \n",
       "3    0        0    3   0          0     0   0    0     0    0    0         0   \n",
       "4    0        1    2   0          0     0   1    0     0    0    1         0   \n",
       "\n",
       "   traveling  was  \n",
       "0          0    0  \n",
       "1          0    1  \n",
       "2          1    1  \n",
       "3          0    0  \n",
       "4          0    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CV = pd.DataFrame( word_count.toarray(), columns=count.get_feature_names_out())\n",
    "df_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed7de4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>awesome</th>\n",
       "      <th>bus</th>\n",
       "      <th>by</th>\n",
       "      <th>expensive</th>\n",
       "      <th>full</th>\n",
       "      <th>is</th>\n",
       "      <th>jim</th>\n",
       "      <th>late</th>\n",
       "      <th>pam</th>\n",
       "      <th>the</th>\n",
       "      <th>traveled</th>\n",
       "      <th>traveling</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    and  awesome   bus    by  expensive  full    is   jim  late   pam   the  \\\n",
       "0  0.14      0.0  0.14  0.14       0.00  0.00  0.00  0.14  0.00  0.14  0.14   \n",
       "1  0.00      0.0  0.25  0.00       0.00  0.00  0.00  0.00  0.25  0.00  0.25   \n",
       "2  0.00      0.0  0.22  0.11       0.11  0.11  0.11  0.00  0.00  0.00  0.11   \n",
       "3  0.00      0.0  1.00  0.00       0.00  0.00  0.00  0.00  0.00  0.00  0.00   \n",
       "4  0.00      0.2  0.40  0.00       0.00  0.00  0.20  0.00  0.00  0.00  0.20   \n",
       "\n",
       "   traveled  traveling   was  \n",
       "0      0.14       0.00  0.00  \n",
       "1      0.00       0.00  0.25  \n",
       "2      0.00       0.11  0.11  \n",
       "3      0.00       0.00  0.00  \n",
       "4      0.00       0.00  0.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term frequency\n",
    "\n",
    "words_in_docs = df_CV.sum(axis=1).astype(float)\n",
    "d = {}\n",
    "for ix, row in df_CV.iterrows():\n",
    "    a = df_CV.iloc[ix] / words_in_docs[ix]\n",
    "    d[ix] = a\n",
    "\n",
    "pd.DataFrame(d).T.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcfe6a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bus</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expensive</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>late</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pam</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1.182322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveled</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveling</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf_weight\n",
       "and          2.098612\n",
       "awesome      2.098612\n",
       "bus          1.000000\n",
       "by           1.693147\n",
       "expensive    2.098612\n",
       "full         2.098612\n",
       "is           1.693147\n",
       "jim          2.098612\n",
       "late         2.098612\n",
       "pam          2.098612\n",
       "the          1.182322\n",
       "traveled     2.098612\n",
       "traveling    2.098612\n",
       "was          1.693147"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just IDF weights\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "X = [\"Jim and Pam traveled by the bus\", \"The bus was late.\", \"The bus was full. Traveling by bus is expensive.\", 'bus bus bus', 'the bus bus is awesome']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)\n",
    "vectorizer.idf_\n",
    "\n",
    "df_idf = pd.DataFrame(vectorizer.idf_).T\n",
    "df_idf.columns = vectorizer.get_feature_names_out()\n",
    "df_idf = df_idf.T\n",
    "df_idf.columns = ['idf_weight']\n",
    "df_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b0f1a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>awesome</th>\n",
       "      <th>bus</th>\n",
       "      <th>by</th>\n",
       "      <th>expensive</th>\n",
       "      <th>full</th>\n",
       "      <th>is</th>\n",
       "      <th>jim</th>\n",
       "      <th>late</th>\n",
       "      <th>pam</th>\n",
       "      <th>the</th>\n",
       "      <th>traveled</th>\n",
       "      <th>traveling</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.439</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     and  awesome    bus     by  expensive   full     is    jim   late    pam  \\\n",
       "0  0.439     0.00  0.209  0.354      0.000  0.000  0.000  0.439  0.000  0.439   \n",
       "1  0.000     0.00  0.322  0.000      0.000  0.000  0.000  0.000  0.675  0.000   \n",
       "2  0.000     0.00  0.383  0.325      0.402  0.402  0.325  0.000  0.000  0.000   \n",
       "3  0.000     0.00  1.000  0.000      0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4  0.000     0.59  0.562  0.000      0.000  0.000  0.476  0.000  0.000  0.000   \n",
       "\n",
       "     the  traveled  traveling    was  \n",
       "0  0.247     0.439      0.000  0.000  \n",
       "1  0.380     0.000      0.000  0.545  \n",
       "2  0.227     0.000      0.402  0.325  \n",
       "3  0.000     0.000      0.000  0.000  \n",
       "4  0.332     0.000      0.000  0.000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full TFIDF vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "X = [\"Jim and Pam traveled by the bus\", \"The bus was late.\", \"The bus was full. Traveling by bus is expensive.\", 'bus bus bus', 'the bus bus is awesome']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)\n",
    "\n",
    "df_tfidf = pd.DataFrame(X.toarray(), columns=count.get_feature_names_out())\n",
    "df_tfidf.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "233c549b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>awesome</th>\n",
       "      <th>bus</th>\n",
       "      <th>by</th>\n",
       "      <th>expensive</th>\n",
       "      <th>full</th>\n",
       "      <th>is</th>\n",
       "      <th>jim</th>\n",
       "      <th>late</th>\n",
       "      <th>pam</th>\n",
       "      <th>the</th>\n",
       "      <th>traveled</th>\n",
       "      <th>traveling</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>1.182322</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.182322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.182322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.182322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and   awesome  bus        by  expensive      full        is       jim  \\\n",
       "0  2.098612  0.000000  1.0  1.693147   0.000000  0.000000  0.000000  2.098612   \n",
       "1  0.000000  0.000000  1.0  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  2.0  1.693147   2.098612  2.098612  1.693147  0.000000   \n",
       "3  0.000000  0.000000  3.0  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  2.098612  2.0  0.000000   0.000000  0.000000  1.693147  0.000000   \n",
       "\n",
       "       late       pam       the  traveled  traveling       was  \n",
       "0  0.000000  2.098612  1.182322  2.098612   0.000000  0.000000  \n",
       "1  2.098612  0.000000  1.182322  0.000000   0.000000  1.693147  \n",
       "2  0.000000  0.000000  1.182322  0.000000   2.098612  1.693147  \n",
       "3  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "4  0.000000  0.000000  1.182322  0.000000   0.000000  0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "X = [\"Jim and Pam traveled by the bus\", \"The bus was late.\", \"The bus was full. Traveling by bus is expensive.\", 'bus bus bus', 'the bus bus is awesome']\n",
    "\n",
    "vectorizer = TfidfVectorizer(norm=None)\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)\n",
    "\n",
    "\n",
    "df_tfidf = pd.DataFrame(X.toarray(), columns=count.get_feature_names_out())\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37dcfc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>awesome</th>\n",
       "      <th>bus</th>\n",
       "      <th>by</th>\n",
       "      <th>expensive</th>\n",
       "      <th>full</th>\n",
       "      <th>is</th>\n",
       "      <th>jim</th>\n",
       "      <th>late</th>\n",
       "      <th>pam</th>\n",
       "      <th>the</th>\n",
       "      <th>traveled</th>\n",
       "      <th>traveling</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and   awesome  bus        by  expensive      full        is       jim  \\\n",
       "0  2.609438  0.000000  1.0  1.916291   0.000000  0.000000  0.000000  2.609438   \n",
       "1  0.000000  0.000000  1.0  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  2.0  1.916291   2.609438  2.609438  1.916291  0.000000   \n",
       "3  0.000000  0.000000  3.0  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  2.609438  2.0  0.000000   0.000000  0.000000  1.916291  0.000000   \n",
       "\n",
       "       late       pam       the  traveled  traveling       was  \n",
       "0  0.000000  2.609438  1.223144  2.609438   0.000000  0.000000  \n",
       "1  2.609438  0.000000  1.223144  0.000000   0.000000  1.916291  \n",
       "2  0.000000  0.000000  1.223144  0.000000   2.609438  1.916291  \n",
       "3  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "4  0.000000  0.000000  1.223144  0.000000   0.000000  0.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "X = [\"Jim and Pam traveled by the bus\", \"The bus was late.\", \"The bus was full. Traveling by bus is expensive.\", 'bus bus bus', 'the bus bus is awesome']\n",
    "\n",
    "vectorizer = TfidfVectorizer(norm=None, smooth_idf=False)\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)\n",
    "\n",
    "\n",
    "df_tfidf = pd.DataFrame(X.toarray(), columns=count.get_feature_names_out())\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9faa8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbfc10a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>awesome</th>\n",
       "      <th>bus</th>\n",
       "      <th>by</th>\n",
       "      <th>expensive</th>\n",
       "      <th>full</th>\n",
       "      <th>is</th>\n",
       "      <th>jim</th>\n",
       "      <th>late</th>\n",
       "      <th>pam</th>\n",
       "      <th>the</th>\n",
       "      <th>traveled</th>\n",
       "      <th>traveling</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603023</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.301511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and   awesome       bus        by  expensive      full        is  \\\n",
       "0  0.377964  0.000000  0.377964  0.377964   0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.500000  0.000000   0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.603023  0.301511   0.301511  0.301511  0.301511   \n",
       "3  0.000000  0.000000  1.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.377964  0.755929  0.000000   0.000000  0.000000  0.377964   \n",
       "\n",
       "        jim  late       pam       the  traveled  traveling       was  \n",
       "0  0.377964   0.0  0.377964  0.377964  0.377964   0.000000  0.000000  \n",
       "1  0.000000   0.5  0.000000  0.500000  0.000000   0.000000  0.500000  \n",
       "2  0.000000   0.0  0.000000  0.301511  0.000000   0.301511  0.301511  \n",
       "3  0.000000   0.0  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "4  0.000000   0.0  0.000000  0.377964  0.000000   0.000000  0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "X = [\"Jim and Pam traveled by the bus\", \"The bus was late.\", \"The bus was full. Traveling by bus is expensive.\", 'bus bus bus', 'the bus bus is awesome']\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=False)\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)\n",
    "\n",
    "\n",
    "df_tfidf = pd.DataFrame(X.toarray(), columns=count.get_feature_names_out())\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d30b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bus</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1.182322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expensive</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>late</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pam</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveled</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveling</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf_weights\n",
       "bus           1.000000\n",
       "the           1.182322\n",
       "by            1.693147\n",
       "is            1.693147\n",
       "was           1.693147\n",
       "and           2.098612\n",
       "awesome       2.098612\n",
       "expensive     2.098612\n",
       "full          2.098612\n",
       "jim           2.098612\n",
       "late          2.098612\n",
       "pam           2.098612\n",
       "traveled      2.098612\n",
       "traveling     2.098612"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this part of code was adapted from Analytics Vidhya by Prateek Majumder \n",
    "# https://www.analyticsvidhya.com/blog/2021/09/creating-a-movie-reviews-classifier-using-tf-idf-in-python/\n",
    "\n",
    "X = [\"Jim and Pam traveled by the bus\", \n",
    "     \"The bus was late.\", \n",
    "     \"The bus was full. Traveling by bus is expensive.\",\n",
    "    'bus bus bus', \n",
    "    'the bus bus is awesome']\n",
    "\n",
    "\n",
    "#using the count vectorizer\n",
    "count = CountVectorizer()\n",
    "word_count=count.fit_transform(X)\n",
    "print(word_count.shape)\n",
    "\n",
    "tfidf_transformer=TfidfTransformer()\n",
    "tfidf_transformer.fit(word_count)\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=count.get_feature_names_out(),columns=[\"idf_weights\"])\n",
    "#inverse document frequency\n",
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ea375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b10a1cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bus</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1.182322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expensive</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>late</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pam</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveled</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveling</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf_weights\n",
       "bus           1.000000\n",
       "the           1.182322\n",
       "by            1.693147\n",
       "is            1.693147\n",
       "was           1.693147\n",
       "and           2.098612\n",
       "awesome       2.098612\n",
       "expensive     2.098612\n",
       "full          2.098612\n",
       "jim           2.098612\n",
       "late          2.098612\n",
       "pam           2.098612\n",
       "traveled      2.098612\n",
       "traveling     2.098612"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this part of code was adapted from Analytics Vidhya by Prateek Majumder \n",
    "# https://www.analyticsvidhya.com/blog/2021/09/creating-a-movie-reviews-classifier-using-tf-idf-in-python/\n",
    "\n",
    "X = [\"Jim and Pam traveled by the bus\", \"The bus was late.\", \"The bus was full. Traveling by bus is expensive.\", 'bus bus bus', 'the bus bus is awesome']\n",
    "\n",
    "\n",
    "#using the count vectorizer\n",
    "count = CountVectorizer()\n",
    "word_count=count.fit_transform(X)\n",
    "print(word_count.shape)\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(norm=None)\n",
    "tfidf_transformer.fit(word_count)\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=count.get_feature_names_out(),columns=[\"idf_weights\"])\n",
    "#inverse document frequency\n",
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47093e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdecode_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstrip_accents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpreprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtoken_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'(?u)\\\\b\\\\w\\\\w+\\\\b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'numpy.float64'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muse_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msmooth_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"Convert a collection of raw documents to a matrix of TF-IDF features.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Equivalent to :class:`CountVectorizer` followed by\u001b[0m\n",
      "\u001b[0;34m    :class:`TfidfTransformer`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For an example of usage, see\u001b[0m\n",
      "\u001b[0;34m    :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For an efficiency comparision of the different feature extractors, see\u001b[0m\n",
      "\u001b[0;34m    :ref:`sphx_glr_auto_examples_text_plot_hashing_vs_dict_vectorizer.py`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Read more in the :ref:`User Guide <text_feature_extraction>`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Parameters\u001b[0m\n",
      "\u001b[0;34m    ----------\u001b[0m\n",
      "\u001b[0;34m    input : {'filename', 'file', 'content'}, default='content'\u001b[0m\n",
      "\u001b[0;34m        - If `'filename'`, the sequence passed as an argument to fit is\u001b[0m\n",
      "\u001b[0;34m          expected to be a list of filenames that need reading to fetch\u001b[0m\n",
      "\u001b[0;34m          the raw content to analyze.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        - If `'file'`, the sequence items must have a 'read' method (file-like\u001b[0m\n",
      "\u001b[0;34m          object) that is called to fetch the bytes in memory.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        - If `'content'`, the input is expected to be a sequence of items that\u001b[0m\n",
      "\u001b[0;34m          can be of type string or byte.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    encoding : str, default='utf-8'\u001b[0m\n",
      "\u001b[0;34m        If bytes or files are given to analyze, this encoding is used to\u001b[0m\n",
      "\u001b[0;34m        decode.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    decode_error : {'strict', 'ignore', 'replace'}, default='strict'\u001b[0m\n",
      "\u001b[0;34m        Instruction on what to do if a byte sequence is given to analyze that\u001b[0m\n",
      "\u001b[0;34m        contains characters not of the given `encoding`. By default, it is\u001b[0m\n",
      "\u001b[0;34m        'strict', meaning that a UnicodeDecodeError will be raised. Other\u001b[0m\n",
      "\u001b[0;34m        values are 'ignore' and 'replace'.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    strip_accents : {'ascii', 'unicode'} or callable, default=None\u001b[0m\n",
      "\u001b[0;34m        Remove accents and perform other character normalization\u001b[0m\n",
      "\u001b[0;34m        during the preprocessing step.\u001b[0m\n",
      "\u001b[0;34m        'ascii' is a fast method that only works on characters that have\u001b[0m\n",
      "\u001b[0;34m        a direct ASCII mapping.\u001b[0m\n",
      "\u001b[0;34m        'unicode' is a slightly slower method that works on any characters.\u001b[0m\n",
      "\u001b[0;34m        None (default) means no character normalization is performed.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Both 'ascii' and 'unicode' use NFKD normalization from\u001b[0m\n",
      "\u001b[0;34m        :func:`unicodedata.normalize`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    lowercase : bool, default=True\u001b[0m\n",
      "\u001b[0;34m        Convert all characters to lowercase before tokenizing.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    preprocessor : callable, default=None\u001b[0m\n",
      "\u001b[0;34m        Override the preprocessing (string transformation) stage while\u001b[0m\n",
      "\u001b[0;34m        preserving the tokenizing and n-grams generation steps.\u001b[0m\n",
      "\u001b[0;34m        Only applies if ``analyzer`` is not callable.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    tokenizer : callable, default=None\u001b[0m\n",
      "\u001b[0;34m        Override the string tokenization step while preserving the\u001b[0m\n",
      "\u001b[0;34m        preprocessing and n-grams generation steps.\u001b[0m\n",
      "\u001b[0;34m        Only applies if ``analyzer == 'word'``.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    analyzer : {'word', 'char', 'char_wb'} or callable, default='word'\u001b[0m\n",
      "\u001b[0;34m        Whether the feature should be made of word or character n-grams.\u001b[0m\n",
      "\u001b[0;34m        Option 'char_wb' creates character n-grams only from text inside\u001b[0m\n",
      "\u001b[0;34m        word boundaries; n-grams at the edges of words are padded with space.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        If a callable is passed it is used to extract the sequence of features\u001b[0m\n",
      "\u001b[0;34m        out of the raw, unprocessed input.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionchanged:: 0.21\u001b[0m\n",
      "\u001b[0;34m            Since v0.21, if ``input`` is ``'filename'`` or ``'file'``, the data\u001b[0m\n",
      "\u001b[0;34m            is first read from the file and then passed to the given callable\u001b[0m\n",
      "\u001b[0;34m            analyzer.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    stop_words : {'english'}, list, default=None\u001b[0m\n",
      "\u001b[0;34m        If a string, it is passed to _check_stop_list and the appropriate stop\u001b[0m\n",
      "\u001b[0;34m        list is returned. 'english' is currently the only supported string\u001b[0m\n",
      "\u001b[0;34m        value.\u001b[0m\n",
      "\u001b[0;34m        There are several known issues with 'english' and you should\u001b[0m\n",
      "\u001b[0;34m        consider an alternative (see :ref:`stop_words`).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        If a list, that list is assumed to contain stop words, all of which\u001b[0m\n",
      "\u001b[0;34m        will be removed from the resulting tokens.\u001b[0m\n",
      "\u001b[0;34m        Only applies if ``analyzer == 'word'``.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        If None, no stop words will be used. In this case, setting `max_df`\u001b[0m\n",
      "\u001b[0;34m        to a higher value, such as in the range (0.7, 1.0), can automatically detect\u001b[0m\n",
      "\u001b[0;34m        and filter stop words based on intra corpus document frequency of terms.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    token_pattern : str, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\"\u001b[0m\n",
      "\u001b[0;34m        Regular expression denoting what constitutes a \"token\", only used\u001b[0m\n",
      "\u001b[0;34m        if ``analyzer == 'word'``. The default regexp selects tokens of 2\u001b[0m\n",
      "\u001b[0;34m        or more alphanumeric characters (punctuation is completely ignored\u001b[0m\n",
      "\u001b[0;34m        and always treated as a token separator).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        If there is a capturing group in token_pattern then the\u001b[0m\n",
      "\u001b[0;34m        captured group content, not the entire match, becomes the token.\u001b[0m\n",
      "\u001b[0;34m        At most one capturing group is permitted.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ngram_range : tuple (min_n, max_n), default=(1, 1)\u001b[0m\n",
      "\u001b[0;34m        The lower and upper boundary of the range of n-values for different\u001b[0m\n",
      "\u001b[0;34m        n-grams to be extracted. All values of n such that min_n <= n <= max_n\u001b[0m\n",
      "\u001b[0;34m        will be used. For example an ``ngram_range`` of ``(1, 1)`` means only\u001b[0m\n",
      "\u001b[0;34m        unigrams, ``(1, 2)`` means unigrams and bigrams, and ``(2, 2)`` means\u001b[0m\n",
      "\u001b[0;34m        only bigrams.\u001b[0m\n",
      "\u001b[0;34m        Only applies if ``analyzer`` is not callable.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    max_df : float or int, default=1.0\u001b[0m\n",
      "\u001b[0;34m        When building the vocabulary ignore terms that have a document\u001b[0m\n",
      "\u001b[0;34m        frequency strictly higher than the given threshold (corpus-specific\u001b[0m\n",
      "\u001b[0;34m        stop words).\u001b[0m\n",
      "\u001b[0;34m        If float in range [0.0, 1.0], the parameter represents a proportion of\u001b[0m\n",
      "\u001b[0;34m        documents, integer absolute counts.\u001b[0m\n",
      "\u001b[0;34m        This parameter is ignored if vocabulary is not None.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    min_df : float or int, default=1\u001b[0m\n",
      "\u001b[0;34m        When building the vocabulary ignore terms that have a document\u001b[0m\n",
      "\u001b[0;34m        frequency strictly lower than the given threshold. This value is also\u001b[0m\n",
      "\u001b[0;34m        called cut-off in the literature.\u001b[0m\n",
      "\u001b[0;34m        If float in range of [0.0, 1.0], the parameter represents a proportion\u001b[0m\n",
      "\u001b[0;34m        of documents, integer absolute counts.\u001b[0m\n",
      "\u001b[0;34m        This parameter is ignored if vocabulary is not None.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    max_features : int, default=None\u001b[0m\n",
      "\u001b[0;34m        If not None, build a vocabulary that only consider the top\u001b[0m\n",
      "\u001b[0;34m        `max_features` ordered by term frequency across the corpus.\u001b[0m\n",
      "\u001b[0;34m        Otherwise, all features are used.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        This parameter is ignored if vocabulary is not None.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    vocabulary : Mapping or iterable, default=None\u001b[0m\n",
      "\u001b[0;34m        Either a Mapping (e.g., a dict) where keys are terms and values are\u001b[0m\n",
      "\u001b[0;34m        indices in the feature matrix, or an iterable over terms. If not\u001b[0m\n",
      "\u001b[0;34m        given, a vocabulary is determined from the input documents.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    binary : bool, default=False\u001b[0m\n",
      "\u001b[0;34m        If True, all non-zero term counts are set to 1. This does not mean\u001b[0m\n",
      "\u001b[0;34m        outputs will have only 0/1 values, only that the tf term in tf-idf\u001b[0m\n",
      "\u001b[0;34m        is binary. (Set `binary` to True, `use_idf` to False and\u001b[0m\n",
      "\u001b[0;34m        `norm` to None to get 0/1 outputs).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    dtype : dtype, default=float64\u001b[0m\n",
      "\u001b[0;34m        Type of the matrix returned by fit_transform() or transform().\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    norm : {'l1', 'l2'} or None, default='l2'\u001b[0m\n",
      "\u001b[0;34m        Each output row will have unit norm, either:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        - 'l2': Sum of squares of vector elements is 1. The cosine\u001b[0m\n",
      "\u001b[0;34m          similarity between two vectors is their dot product when l2 norm has\u001b[0m\n",
      "\u001b[0;34m          been applied.\u001b[0m\n",
      "\u001b[0;34m        - 'l1': Sum of absolute values of vector elements is 1.\u001b[0m\n",
      "\u001b[0;34m          See :func:`~sklearn.preprocessing.normalize`.\u001b[0m\n",
      "\u001b[0;34m        - None: No normalization.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    use_idf : bool, default=True\u001b[0m\n",
      "\u001b[0;34m        Enable inverse-document-frequency reweighting. If False, idf(t) = 1.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    smooth_idf : bool, default=True\u001b[0m\n",
      "\u001b[0;34m        Smooth idf weights by adding one to document frequencies, as if an\u001b[0m\n",
      "\u001b[0;34m        extra document was seen containing every term in the collection\u001b[0m\n",
      "\u001b[0;34m        exactly once. Prevents zero divisions.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    sublinear_tf : bool, default=False\u001b[0m\n",
      "\u001b[0;34m        Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Attributes\u001b[0m\n",
      "\u001b[0;34m    ----------\u001b[0m\n",
      "\u001b[0;34m    vocabulary_ : dict\u001b[0m\n",
      "\u001b[0;34m        A mapping of terms to feature indices.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    fixed_vocabulary_ : bool\u001b[0m\n",
      "\u001b[0;34m        True if a fixed vocabulary of term to indices mapping\u001b[0m\n",
      "\u001b[0;34m        is provided by the user.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    idf_ : array of shape (n_features,)\u001b[0m\n",
      "\u001b[0;34m        The inverse document frequency (IDF) vector; only defined\u001b[0m\n",
      "\u001b[0;34m        if ``use_idf`` is True.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    stop_words_ : set\u001b[0m\n",
      "\u001b[0;34m        Terms that were ignored because they either:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m          - occurred in too many documents (`max_df`)\u001b[0m\n",
      "\u001b[0;34m          - occurred in too few documents (`min_df`)\u001b[0m\n",
      "\u001b[0;34m          - were cut off by feature selection (`max_features`).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        This is only available if no vocabulary was given.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    See Also\u001b[0m\n",
      "\u001b[0;34m    --------\u001b[0m\n",
      "\u001b[0;34m    CountVectorizer : Transforms text into a sparse matrix of n-gram counts.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    TfidfTransformer : Performs the TF-IDF transformation from a provided\u001b[0m\n",
      "\u001b[0;34m        matrix of counts.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Notes\u001b[0m\n",
      "\u001b[0;34m    -----\u001b[0m\n",
      "\u001b[0;34m    The ``stop_words_`` attribute can get large and increase the model size\u001b[0m\n",
      "\u001b[0;34m    when pickling. This attribute is provided only for introspection and can\u001b[0m\n",
      "\u001b[0;34m    be safely removed using delattr or set to None before pickling.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Examples\u001b[0m\n",
      "\u001b[0;34m    --------\u001b[0m\n",
      "\u001b[0;34m    >>> from sklearn.feature_extraction.text import TfidfVectorizer\u001b[0m\n",
      "\u001b[0;34m    >>> corpus = [\u001b[0m\n",
      "\u001b[0;34m    ...     'This is the first document.',\u001b[0m\n",
      "\u001b[0;34m    ...     'This document is the second document.',\u001b[0m\n",
      "\u001b[0;34m    ...     'And this is the third one.',\u001b[0m\n",
      "\u001b[0;34m    ...     'Is this the first document?',\u001b[0m\n",
      "\u001b[0;34m    ... ]\u001b[0m\n",
      "\u001b[0;34m    >>> vectorizer = TfidfVectorizer()\u001b[0m\n",
      "\u001b[0;34m    >>> X = vectorizer.fit_transform(corpus)\u001b[0m\n",
      "\u001b[0;34m    >>> vectorizer.get_feature_names_out()\u001b[0m\n",
      "\u001b[0;34m    array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\u001b[0m\n",
      "\u001b[0;34m           'this'], ...)\u001b[0m\n",
      "\u001b[0;34m    >>> print(X.shape)\u001b[0m\n",
      "\u001b[0;34m    (4, 9)\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"norm\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStrOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"l1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"use_idf\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"boolean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"smooth_idf\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"boolean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"sublinear_tf\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"boolean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdecode_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstrip_accents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpreprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtoken_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr\"(?u)\\b\\w\\w+\\b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0muse_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msmooth_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdecode_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstrip_accents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrip_accents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpreprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtoken_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_pattern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_idf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_idf\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_idf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_idf\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msublinear_tf\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Broadcast the TF-IDF parameters to the underlying transformer instance\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# for easy grid search and repr\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0midf_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Inverse document frequency vector, only defined if `use_idf=True`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns\u001b[0m\n",
      "\u001b[0;34m        -------\u001b[0m\n",
      "\u001b[0;34m        ndarray of shape (n_features,)\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_tfidf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"{self.__class__.__name__} is not fitted yet. Call 'fit' with \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"appropriate arguments before using this attribute.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midf_\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0midf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0midf_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_idf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`idf_` cannot be set when `user_idf=False`.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_tfidf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# We should support transferring `idf_` from another `TfidfTransformer`\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# and therefore, we need to create the transformer instance it does not\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# exist yet.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0muse_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_idf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0msmooth_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_idf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"vocabulary_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"idf length = %d must be equal to vocabulary size = %d\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Only {} 'dtype' should be used. {} 'dtype' will \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"be converted to np.float64.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mUserWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Learn vocabulary and idf from training set.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        raw_documents : iterable\u001b[0m\n",
      "\u001b[0;34m            An iterable which generates either str, unicode or file objects.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        y : None\u001b[0m\n",
      "\u001b[0;34m            This parameter is not needed to compute tfidf.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns\u001b[0m\n",
      "\u001b[0;34m        -------\u001b[0m\n",
      "\u001b[0;34m        self : object\u001b[0m\n",
      "\u001b[0;34m            Fitted vectorizer.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0muse_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_idf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0msmooth_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_idf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Learn vocabulary and idf, return document-term matrix.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        This is equivalent to fit followed by transform, but more efficiently\u001b[0m\n",
      "\u001b[0;34m        implemented.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        raw_documents : iterable\u001b[0m\n",
      "\u001b[0;34m            An iterable which generates either str, unicode or file objects.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        y : None\u001b[0m\n",
      "\u001b[0;34m            This parameter is ignored.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns\u001b[0m\n",
      "\u001b[0;34m        -------\u001b[0m\n",
      "\u001b[0;34m        X : sparse matrix of (n_samples, n_features)\u001b[0m\n",
      "\u001b[0;34m            Tf-idf-weighted document-term matrix.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0muse_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_idf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0msmooth_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_idf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# we set copy to False\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Transform documents to document-term matrix.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Uses the vocabulary and document frequencies (df) learned by fit (or\u001b[0m\n",
      "\u001b[0;34m        fit_transform).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        raw_documents : iterable\u001b[0m\n",
      "\u001b[0;34m            An iterable which generates either str, unicode or file objects.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns\u001b[0m\n",
      "\u001b[0;34m        -------\u001b[0m\n",
      "\u001b[0;34m        X : sparse matrix of (n_samples, n_features)\u001b[0m\n",
      "\u001b[0;34m            Tf-idf-weighted document-term matrix.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"The TF-IDF vectorizer is not fitted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"X_types\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_skip_test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "TfidfVectorizer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b02b6b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>late</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1.182322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bus</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expensive</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pam</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveled</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveling</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tfidf\n",
       "late       2.098612\n",
       "was        1.693147\n",
       "the        1.182322\n",
       "bus        1.000000\n",
       "and        0.000000\n",
       "awesome    0.000000\n",
       "by         0.000000\n",
       "expensive  0.000000\n",
       "full       0.000000\n",
       "is         0.000000\n",
       "jim        0.000000\n",
       "pam        0.000000\n",
       "traveled   0.000000\n",
       "traveling  0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector=tfidf_transformer.transform(word_count)\n",
    "feature_names = count.get_feature_names_out()\n",
    "first_document_vector=tf_idf_vector[1]\n",
    "df_tfifd= pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "df_tfifd.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bdfdf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program  :  program\n",
      "programs  :  program\n",
      "programmer  :  programm\n",
      "programming  :  program\n",
      "programmers  :  programm\n"
     ]
    }
   ],
   "source": [
    "## Another example taken from geeksforgeeks.com\n",
    "# import these modules\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# choose some words to be stemmed\n",
    "words = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmers\"]\n",
    "\n",
    "for w in words:\n",
    "    print(w, \" : \", ps.stem(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb3171e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n",
      "better : better\n"
     ]
    }
   ],
   "source": [
    "# import these modules  via geeksforgeeks\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
    "\n",
    "# a denotes adjective in \"pos\"\n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d161e850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>awesome</th>\n",
       "      <th>bus</th>\n",
       "      <th>by</th>\n",
       "      <th>expensive</th>\n",
       "      <th>full</th>\n",
       "      <th>is</th>\n",
       "      <th>jim</th>\n",
       "      <th>late</th>\n",
       "      <th>pam</th>\n",
       "      <th>the</th>\n",
       "      <th>traveled</th>\n",
       "      <th>traveling</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209054</td>\n",
       "      <td>0.353960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.247170</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.67491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383407</td>\n",
       "      <td>0.324583</td>\n",
       "      <td>0.402312</td>\n",
       "      <td>0.402312</td>\n",
       "      <td>0.324583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402312</td>\n",
       "      <td>0.324583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589609</td>\n",
       "      <td>0.561904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.332176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and   awesome       bus        by  expensive      full        is  \\\n",
       "0  0.438724  0.000000  0.209054  0.353960   0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.321598  0.000000   0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.383407  0.324583   0.402312  0.402312  0.324583   \n",
       "3  0.000000  0.000000  1.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.589609  0.561904  0.000000   0.000000  0.000000  0.475693   \n",
       "\n",
       "        jim     late       pam       the  traveled  traveling       was  \n",
       "0  0.438724  0.00000  0.438724  0.247170  0.438724   0.000000  0.000000  \n",
       "1  0.000000  0.67491  0.000000  0.380232  0.000000   0.000000  0.544513  \n",
       "2  0.000000  0.00000  0.000000  0.226655  0.000000   0.402312  0.324583  \n",
       "3  0.000000  0.00000  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "4  0.000000  0.00000  0.000000  0.332176  0.000000   0.000000  0.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5888612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>awesome</th>\n",
       "      <th>bus</th>\n",
       "      <th>by</th>\n",
       "      <th>expensive</th>\n",
       "      <th>full</th>\n",
       "      <th>is</th>\n",
       "      <th>jim</th>\n",
       "      <th>late</th>\n",
       "      <th>pam</th>\n",
       "      <th>the</th>\n",
       "      <th>traveled</th>\n",
       "      <th>traveling</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.098612</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>1.182322</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and   awesome  bus        by  expensive      full        is       jim  \\\n",
       "0  2.098612  2.098612  1.0  1.693147   2.098612  2.098612  1.693147  2.098612   \n",
       "\n",
       "       late       pam       the  traveled  traveling       was  \n",
       "0  2.098612  2.098612  1.182322  2.098612   2.098612  1.693147  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfidf = pd.DataFrame(vectorizer.idf_).T\n",
    "\n",
    "dfidf.columns = vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "dfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a48b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f46ac51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df_tfidf, cmap='crest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d2c53b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d290a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
